{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e77390a-0c25-4d70-a3af-4d9b227c58a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32db367-9f11-47b5-8172-493387f69a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc717370-2610-4a2a-8991-310aab2aa69a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from databricks.labs.dqx import check_funcs\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.labs.dqx.rule import DQRowRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e337b489-a798-459f-97bd-b711c4b71cc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [\n",
    "    (\"\", \"abc@example.com\"),\n",
    "    (2, None),\n",
    "    (3, \"kafka@example.com\"),\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"email_address\"]\n",
    "input_df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "display(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c993f485-c334-415f-b79d-86093963ec24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checks_yaml_str = \"\"\"\n",
    "# checks.yml file\n",
    "# Error: rows with null or empty `id` are quarantined under `_errors`.\n",
    "# Warn: rows with null or empty `email_address` are quarantined under `_warnings`.\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_not_null_and_not_empty\n",
    "    arguments:\n",
    "      column: id\n",
    "\n",
    "- criticality: warn\n",
    "  check:\n",
    "    function: is_not_null_and_not_empty\n",
    "    arguments:\n",
    "      column: email_address\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63084dfd-0350-4421-bee6-5b9ca9df06f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dq_engine = DQEngine(WorkspaceClient())\n",
    "\n",
    "# Load the checks YAML string into a Python dictionary\n",
    "checks = yaml.safe_load(checks_yaml_str)\n",
    "\n",
    "# Apply checks and automatically split the dataframe into valid and quarantined rows\n",
    "valid_df, quarantine_df = dq_engine.apply_checks_by_metadata_and_split(input_df, checks)\n",
    "\n",
    "print(\"\\nValid Rows (passed all checks):\")\n",
    "display(valid_df)\n",
    "\n",
    "print(\"\\nQuarantined Rows (failed one or more checks):\")\n",
    "display(quarantine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b538e9f5-4fee-4f8a-b6cd-3e09e7dcb12f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple data quality rule in Python to check that email_address is not null or empty\n",
    "checks = [\n",
    "    DQRowRule(\n",
    "        criticality=\"error\",\n",
    "        check_func=check_funcs.is_not_null_and_not_empty,\n",
    "        column=\"id\",\n",
    "    ),\n",
    "    DQRowRule(\n",
    "        criticality=\"warn\",\n",
    "        check_func=check_funcs.is_not_null_and_not_empty,\n",
    "        column=\"email_address\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Apply the rule and automatically split the DataFrame into valid and quarantined rows\n",
    "valid_df, quarantine_df = dq_engine.apply_checks_and_split(input_df, checks)\n",
    "\n",
    "print(\"\\nValid Rows (passed all checks):\")\n",
    "display(valid_df)\n",
    "\n",
    "print(\"\\nQuarantined Rows (failed one or more checks):\")\n",
    "display(quarantine_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "severity_flags_in_dqx",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
